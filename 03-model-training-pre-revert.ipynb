{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.link_prediction import jaccard_coefficient\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import normalized data\n",
    "with open('03-normalized-data/predictors.pkl', 'rb') as f:\n",
    "    predictors = pickle.load(f)\n",
    "\n",
    "baseline_p = predictors[5] # Remove the baseline predictor from the predictors\n",
    "\n",
    "predictors = predictors[:5]\n",
    "\n",
    "\n",
    "# Save data for later use\n",
    "\n",
    "\n",
    "\n",
    "# Import edgenonedge data\n",
    "with open('04-edgenonedge-data/edgenonedge_data.pkl', 'rb') as f:\n",
    "    edgenonedge_data = pickle.load(f)\n",
    "\n",
    "# Save data \n",
    "with open('05-edge-metadata/edge_metadata.pkl', 'rb') as f:\n",
    "    edge_metadata = pickle.load(f)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "predictor_names = ['Jaccard Coefficient', 'Adamic-Adar Index', 'Geodesic Distance',\n",
    "                   'Common Neighbors', 'Degree Product']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample edge prediction score: [2.86248008e-11]\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "g = 0\n",
    "e = 5\n",
    "print('Sample edge prediction score:', predictors[p][g][e])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of edge metadata for first 10 graphs\n",
      "(363242, 16)\n",
      "(353268, 16)\n",
      "(280912, 16)\n",
      "(179705, 16)\n",
      "(99249, 16)\n",
      "(313918, 16)\n",
      "(174885, 16)\n",
      "(507329, 16)\n",
      "(296717, 16)\n",
      "(168504, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# FEATURES\n",
    "# edge_metadata is the features, we don't need to edit it\n",
    "# Lets examine the data rq...\n",
    "print('Shape of edge metadata for first 10 graphs')\n",
    "for i in range(10):\n",
    "    print(edge_metadata[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS\n",
    "# The labels will be the index of the 'most correct' predictor\n",
    "# If the edge actually exists, the 'most correct' predictor is the one with the highest score.\n",
    "# If it doesn't exist, the 'most correct' predictor has the lowest score.\n",
    "\n",
    "mces = []  # Place to store the most correct estimators for each graph\n",
    "\n",
    "for g in range(len(edgenonedge_data)):  # Iterate over each graph\n",
    "    g1_predictions = []\n",
    "\n",
    "    for predictor in predictors:\n",
    "        g1_predictions.append(predictor[g])\n",
    "    g1_predictions = np.array(g1_predictions)\n",
    "\n",
    "    g_ene = edgenonedge_data[g]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Find the most correct predictor for each edge (column-wise)\n",
    "    most_correct_estimator = []\n",
    "    edge_is_real = g_ene\n",
    "\n",
    "    for i in range(g1_predictions.shape[1]):  # Iterate over each edge (column index)\n",
    "        if edge_is_real[i]: # If missing edge is an edge in the origional graph\n",
    "            index = np.argmax(g1_predictions[:, i])  # Find the predictor (row) with the maximum value for the edge\n",
    "            most_correct_estimator.append(index)\n",
    "        else:\n",
    "            index = np.argmin(g1_predictions[:, i])  # Find the predictor (row) with the lowest value for the edge\n",
    "            most_correct_estimator.append(index)\n",
    "\n",
    "    # Convert the result to a NumPy array\n",
    "    most_correct_estimator = np.array(most_correct_estimator).reshape(-1, 1)\n",
    "\n",
    "    # Append to the global list\n",
    "    mces.append(most_correct_estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Most-Correct-Estimator data for first 10 graphs:\n",
      "(363242, 1)\n",
      "(353268, 1)\n",
      "(280912, 1)\n",
      "(179705, 1)\n",
      "(99249, 1)\n",
      "(313918, 1)\n",
      "(174885, 1)\n",
      "(507329, 1)\n",
      "(296717, 1)\n",
      "(168504, 1)\n",
      "Sample mce data for first graph: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [3]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the most correct estimator data for the first 10 graphs\n",
    "print(\"Shape of Most-Correct-Estimator data for first 10 graphs:\")\n",
    "for i in range(min(10, len(mces))):  # Limit to 10 graphs or fewer if fewer graphs exist\n",
    "    print(mces[i].shape)\n",
    "\n",
    "print(\"Sample mce data for first graph:\", mces[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Inputs to custom_train_test_split...\n",
      "Test size: 0.2\n",
      "Random state: None\n",
      "Number of graphs in edge_metadata: 26\n",
      "\n",
      "Inspecting edge_metadata[0]:\n",
      "  Shape: (363242, 16)\n",
      "  First 3 sample rows:\n",
      "    Row 0: [ 1.61000000e+02  2.00000000e+00  4.00512687e-02  6.20650058e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.17283951e-03\n",
      "  2.41363138e-01  2.00000000e+00  1.00000000e+00  3.22000000e+02]\n",
      "    Row 1: [ 1.61000000e+02  3.00000000e+00  4.00512687e-02  7.79806973e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.13496933e-03\n",
      "  2.19593112e-01  2.00000000e+00  1.00000000e+00  4.83000000e+02]\n",
      "    Row 2: [ 1.61000000e+02  4.00000000e+00  4.00512687e-02  9.72611570e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.09756098e-03\n",
      "  2.71085031e-01  2.00000000e+00  1.00000000e+00  6.44000000e+02]\n",
      "\n",
      "Inspecting edge_metadata[1]:\n",
      "  Shape: (353268, 16)\n",
      "  First 3 sample rows:\n",
      "    Row 0: [ 1.55000000e+02  2.00000000e+00  4.19646992e-02  6.28361975e-04\n",
      "  8.43000000e+02  1.63500000e+03  4.60689259e-03  3.87900356e+00\n",
      " -1.00000000e+00  1.00000000e+01  6.84622671e-02  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  3.10000000e+02]\n",
      "    Row 1: [ 1.55000000e+02  2.00000000e+00  4.19646992e-02  7.10571645e-04\n",
      "  8.43000000e+02  1.63500000e+03  4.60689259e-03  3.87900356e+00\n",
      " -1.00000000e+00  1.00000000e+01  6.84622671e-02  1.29032258e-02\n",
      "  1.01255420e+00  2.00000000e+00  2.00000000e+00  3.10000000e+02]\n",
      "    Row 2: [ 1.55000000e+02  2.00000000e+00  4.19646992e-02  6.69679396e-04\n",
      "  8.43000000e+02  1.63500000e+03  4.60689259e-03  3.87900356e+00\n",
      " -1.00000000e+00  1.00000000e+01  6.84622671e-02  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  3.10000000e+02]\n",
      "\n",
      "Inspecting edge_metadata[2]:\n",
      "  Shape: (280912, 16)\n",
      "  First 3 sample rows:\n",
      "    Row 0: [ 1.29000000e+02  4.60000000e+01  3.80299094e-02  1.28452481e-02\n",
      "  7.52000000e+02  1.46400000e+03  5.18457659e-03  3.89361702e+00\n",
      " -1.00000000e+00  1.10000000e+01  6.71480361e-02  6.06060606e-02\n",
      "  5.47503558e+00  2.00000000e+00  1.00000000e+01  5.93400000e+03]\n",
      "    Row 1: [ 1.29000000e+02  3.00000000e+00  3.80299094e-02  9.95656140e-04\n",
      "  7.52000000e+02  1.46400000e+03  5.18457659e-03  3.89361702e+00\n",
      " -1.00000000e+00  1.10000000e+01  6.71480361e-02  7.63358779e-03\n",
      "  2.47337947e-01  2.00000000e+00  1.00000000e+00  3.87000000e+02]\n",
      "    Row 2: [ 1.29000000e+02  4.00000000e+00  3.80299094e-02  1.39462326e-03\n",
      "  7.52000000e+02  1.46400000e+03  5.18457659e-03  3.89361702e+00\n",
      " -1.00000000e+00  1.10000000e+01  6.71480361e-02  1.52671756e-02\n",
      "  5.70853400e-01  2.00000000e+00  2.00000000e+00  5.16000000e+02]\n",
      "\n",
      "Number of graphs in mces: 26\n",
      "\n",
      "Inspecting mces[0]:\n",
      "  Shape: (363242, 1)\n",
      "  First 3 sample labels: [[0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Inspecting mces[1]:\n",
      "  Shape: (353268, 1)\n",
      "  First 3 sample labels: [[0]\n",
      " [0]\n",
      " [3]]\n",
      "\n",
      "Inspecting mces[2]:\n",
      "  Shape: (280912, 1)\n",
      "  First 3 sample labels: [[4]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Input inspection complete.\n"
     ]
    }
   ],
   "source": [
    "def inspect_custom_train_test_split_inputs(edge_metadata, mces, test_size, random_state):\n",
    "    \"\"\"\n",
    "    Inspect the inputs to custom_train_test_split to verify their validity.\n",
    "\n",
    "    Args:\n",
    "        edge_metadata (list of np.ndarray): Feature data for each graph.\n",
    "        mces (list of np.ndarray): Label data for each graph.\n",
    "        test_size (float): Fraction of the data to be used for testing.\n",
    "        random_state (int, optional): Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    print(\"Inspecting Inputs to custom_train_test_split...\")\n",
    "\n",
    "    # Check test_size and random_state\n",
    "    print(f\"Test size: {test_size}\")\n",
    "    print(f\"Random state: {random_state}\")\n",
    "\n",
    "    # Check edge_metadata\n",
    "    print(f\"Number of graphs in edge_metadata: {len(edge_metadata)}\")\n",
    "    for i in range(min(3, len(edge_metadata))):  # Inspect the first few graphs\n",
    "        print(f\"\\nInspecting edge_metadata[{i}]:\")\n",
    "        print(f\"  Shape: {edge_metadata[i].shape}\")\n",
    "        print(f\"  First 3 sample rows:\")\n",
    "        for j in range(min(3, edge_metadata[i].shape[0])):  # Print first 3 rows if available\n",
    "            print(f\"    Row {j}: {edge_metadata[i][j]}\")\n",
    "\n",
    "    # Check mces\n",
    "    print(f\"\\nNumber of graphs in mces: {len(mces)}\")\n",
    "    for i in range(min(3, len(mces))):  # Inspect the first few graphs\n",
    "        print(f\"\\nInspecting mces[{i}]:\")\n",
    "        print(f\"  Shape: {mces[i].shape}\")\n",
    "        print(f\"  First 3 sample labels: {mces[i][:3]}\")\n",
    "\n",
    "    # Check alignment of edge_metadata and mces\n",
    "    assert len(edge_metadata) == len(mces), \"Mismatch: edge_metadata and mces must have the same number of graphs!\"\n",
    "    for i in range(len(edge_metadata)):\n",
    "        assert edge_metadata[i].shape[0] == mces[i].shape[0], (\n",
    "            f\"Mismatch: edge_metadata[{i}] and mces[{i}] must have the same number of rows!\"\n",
    "        )\n",
    "\n",
    "    print(\"\\nInput inspection complete.\")\n",
    "\n",
    "# Call the function\n",
    "inspect_custom_train_test_split_inputs(edge_metadata, mces, test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle  # Utility for shuffling data\n",
    "\n",
    "def custom_train_test_split(edge_metadata, mces, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Custom function to split graph-level data into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        edge_metadata (list of np.ndarray): Feature data for each graph.\n",
    "        mces (list of np.ndarray): Label data for each graph.\n",
    "        test_size (float): Fraction of the data to be used for testing.\n",
    "        random_state (int, optional): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        X_train_combined (np.ndarray): Combined and shuffled training data for all graphs.\n",
    "        y_train_combined (np.ndarray): Combined and shuffled training labels for all graphs.\n",
    "        X_test (list of np.ndarray): List of testing data for each graph.\n",
    "        y_test (list of np.ndarray): List of testing labels for each graph.\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Determine the number of graphs\n",
    "    num_graphs = len(edge_metadata)\n",
    "\n",
    "    # Create a shuffled list of graph indices\n",
    "    shuffled_indices = np.random.permutation(num_graphs)\n",
    "\n",
    "    # Split indices into training and testing\n",
    "    split_idx = int((1 - test_size) * num_graphs)\n",
    "    train_indices = shuffled_indices[:split_idx]\n",
    "    test_indices = shuffled_indices[split_idx:]\n",
    "\n",
    "    # Split the data\n",
    "    X_train = [edge_metadata[i] for i in train_indices]\n",
    "    y_train = [mces[i] for i in train_indices]\n",
    "    X_test = [edge_metadata[i] for i in test_indices]\n",
    "    y_test = [mces[i] for i in test_indices]\n",
    "\n",
    "    # Combine training data into single arrays\n",
    "    X_train_combined = np.vstack(X_train)\n",
    "    y_train_combined = np.vstack(y_train)\n",
    "\n",
    "    # Shuffle the combined training data\n",
    "    X_train_combined, y_train_combined = shuffle(X_train_combined, y_train_combined, random_state=random_state)\n",
    "\n",
    "    return X_train_combined, y_train_combined, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test =  custom_train_test_split(edge_metadata, mces, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4810004, 16)\n",
      "y_train shape: (4810004, 1)\n",
      "Sample X_train row: [ 4.00000000e+00  3.00000000e+00  1.19261269e-03  7.92654288e-04\n",
      "  8.68000000e+02  1.75300000e+03  4.65878951e-03  4.03917051e+00\n",
      " -1.00000000e+00  1.00000000e+01  8.49378538e-02  0.00000000e+00\n",
      "  0.00000000e+00  4.00000000e+00  0.00000000e+00  1.20000000e+01]\n",
      "Sample y_train label: [3]\n",
      "Sample X_train row: [ 2.00000000e+00  2.00000000e+00  6.36009151e-04  6.97667192e-04\n",
      "  7.61000000e+02  1.59200000e+03  5.50522166e-03  4.18396846e+00\n",
      " -1.00000000e+00  1.20000000e+01  1.05207474e-01  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  4.00000000e+00]\n",
      "Sample y_train label: [3]\n",
      "Sample X_train row: [ 1.00000000e+00  3.00000000e+00  3.17028706e-04  9.00036755e-04\n",
      "  1.01000000e+03  2.21600000e+03  4.34897801e-03  4.38811881e+00\n",
      " -1.00000000e+00  1.20000000e+01  9.90114922e-02  0.00000000e+00\n",
      "  0.00000000e+00  5.00000000e+00  0.00000000e+00  3.00000000e+00]\n",
      "Sample y_train label: [3]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "for i in range(3):\n",
    "    print(\"Sample X_train row:\", X_train[i])\n",
    "    print(\"Sample y_train label:\", y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0: [ 4.00000000e+00  3.00000000e+00  1.19261269e-03  7.92654288e-04\n",
      "  8.68000000e+02  1.75300000e+03  4.65878951e-03  4.03917051e+00\n",
      " -1.00000000e+00  1.00000000e+01  8.49378538e-02  0.00000000e+00\n",
      "  0.00000000e+00  4.00000000e+00  0.00000000e+00  1.20000000e+01]\n",
      "Row 1: [ 2.00000000e+00  2.00000000e+00  6.36009151e-04  6.97667192e-04\n",
      "  7.61000000e+02  1.59200000e+03  5.50522166e-03  4.18396846e+00\n",
      " -1.00000000e+00  1.20000000e+01  1.05207474e-01  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  4.00000000e+00]\n",
      "Row 2: [ 1.00000000e+00  3.00000000e+00  3.17028706e-04  9.00036755e-04\n",
      "  1.01000000e+03  2.21600000e+03  4.34897801e-03  4.38811881e+00\n",
      " -1.00000000e+00  1.20000000e+01  9.90114922e-02  0.00000000e+00\n",
      "  0.00000000e+00  5.00000000e+00  0.00000000e+00  3.00000000e+00]\n",
      "Row 3: [ 2.00000000e+00  2.00000000e+00  6.09951159e-04  6.74972793e-04\n",
      "  8.68000000e+02  1.75300000e+03  4.65878951e-03  4.03917051e+00\n",
      " -1.00000000e+00  1.00000000e+01  8.49378538e-02  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  4.00000000e+00]\n",
      "Row 4: [ 1.20000000e+01  2.00000000e+00  4.21426445e-03  1.09759823e-03\n",
      "  5.29000000e+02  1.03400000e+03  7.40390674e-03  3.90926276e+00\n",
      " -1.00000000e+00  1.00000000e+01  7.66689287e-02  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  2.40000000e+01]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Row {i}: {X_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4810004, 16)\n",
      "y_train shape: (4810004, 1)\n",
      "Unique rows in X_train: 3338305\n",
      "Unique labels in y_train: [0 1 2 3 4]\n",
      "First 5 rows of X_train:\n",
      " [[ 4.00000000e+00  3.00000000e+00  1.19261269e-03  7.92654288e-04\n",
      "   8.68000000e+02  1.75300000e+03  4.65878951e-03  4.03917051e+00\n",
      "  -1.00000000e+00  1.00000000e+01  8.49378538e-02  0.00000000e+00\n",
      "   0.00000000e+00  4.00000000e+00  0.00000000e+00  1.20000000e+01]\n",
      " [ 2.00000000e+00  2.00000000e+00  6.36009151e-04  6.97667192e-04\n",
      "   7.61000000e+02  1.59200000e+03  5.50522166e-03  4.18396846e+00\n",
      "  -1.00000000e+00  1.20000000e+01  1.05207474e-01  0.00000000e+00\n",
      "   0.00000000e+00  3.00000000e+00  0.00000000e+00  4.00000000e+00]\n",
      " [ 1.00000000e+00  3.00000000e+00  3.17028706e-04  9.00036755e-04\n",
      "   1.01000000e+03  2.21600000e+03  4.34897801e-03  4.38811881e+00\n",
      "  -1.00000000e+00  1.20000000e+01  9.90114922e-02  0.00000000e+00\n",
      "   0.00000000e+00  5.00000000e+00  0.00000000e+00  3.00000000e+00]\n",
      " [ 2.00000000e+00  2.00000000e+00  6.09951159e-04  6.74972793e-04\n",
      "   8.68000000e+02  1.75300000e+03  4.65878951e-03  4.03917051e+00\n",
      "  -1.00000000e+00  1.00000000e+01  8.49378538e-02  0.00000000e+00\n",
      "   0.00000000e+00  3.00000000e+00  0.00000000e+00  4.00000000e+00]\n",
      " [ 1.20000000e+01  2.00000000e+00  4.21426445e-03  1.09759823e-03\n",
      "   5.29000000e+02  1.03400000e+03  7.40390674e-03  3.90926276e+00\n",
      "  -1.00000000e+00  1.00000000e+01  7.66689287e-02  0.00000000e+00\n",
      "   0.00000000e+00  3.00000000e+00  0.00000000e+00  2.40000000e+01]]\n",
      "First 5 labels in y_train:\n",
      " [[3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# With all 0.8 training data from metabolic networks, took 7.5 min to train\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes Classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the Model\n",
    "nb.fit(X_train, y_train.ravel())  # Ensure y_train is a 1D array for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.13      0.22      6811\n",
      "           1       0.89      0.13      0.23     24495\n",
      "           2       0.05      0.05      0.05        42\n",
      "           3       0.46      0.99      0.63     22148\n",
      "           4       0.04      0.28      0.07       158\n",
      "\n",
      "    accuracy                           0.49     53654\n",
      "   macro avg       0.40      0.32      0.24     53654\n",
      "weighted avg       0.67      0.49      0.39     53654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "g = 0  # Test on the first graph of the testing graphs\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = nb.predict(X_test[g])\n",
    "\n",
    "# Evaluate the Model\n",
    "accuracy = accuracy_score(y_test[g], y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test[g], y_pred))\n",
    "\n",
    "# # Feature Importances\n",
    "# print(\"\\nFeature Importances:\")\n",
    "# feature_importances = nb.feature_importances_  # Get feature importances from the model\n",
    "# feature_names = [f\"Feature {i}\" for i in range(X_train.shape[1])]  # Name the features generically\n",
    "\n",
    "# for feature, importance in zip(feature_names, feature_importances):\n",
    "#     print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 81\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m average_scores \u001b[38;5;241m=\u001b[39m compute_average_scores_from_split(edge_metadata, edgenonedge_data, predictors, predictor_names)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m predictor, scores \u001b[38;5;129;01min\u001b[39;00m average_scores\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[22], line 55\u001b[0m, in \u001b[0;36mcompute_average_scores_from_split\u001b[0;34m(edge_metadata, edgenonedge_data, predictors, predictor_names, test_size, random_state)\u001b[0m\n\u001b[1;32m     53\u001b[0m test_metadata \u001b[38;5;241m=\u001b[39m [edge_metadata[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_indices]\n\u001b[1;32m     54\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m [edgenonedge_data[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_indices]\n\u001b[0;32m---> 55\u001b[0m test_predictors \u001b[38;5;241m=\u001b[39m [predictors[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_indices]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Flatten test data for evaluation\u001b[39;00m\n\u001b[1;32m     58\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(test_metadata)\n",
      "Cell \u001b[0;32mIn[22], line 55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m test_metadata \u001b[38;5;241m=\u001b[39m [edge_metadata[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_indices]\n\u001b[1;32m     54\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m [edgenonedge_data[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_indices]\n\u001b[0;32m---> 55\u001b[0m test_predictors \u001b[38;5;241m=\u001b[39m [predictors[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_indices]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Flatten test data for evaluation\u001b[39;00m\n\u001b[1;32m     58\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(test_metadata)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Import normalized data\n",
    "with open('03-normalized-data/predictors.pkl', 'rb') as f:\n",
    "    predictors = pickle.load(f)\n",
    "\n",
    "baseline_p = predictors[5]  # Remove the baseline predictor from the predictors\n",
    "predictors = predictors[:5]\n",
    "\n",
    "# Import edgenonedge data\n",
    "with open('04-edgenonedge-data/edgenonedge_data.pkl', 'rb') as f:\n",
    "    edgenonedge_data = pickle.load(f)\n",
    "\n",
    "# Import edge metadata\n",
    "with open('05-edge-metadata/edge_metadata.pkl', 'rb') as f:\n",
    "    edge_metadata = pickle.load(f)\n",
    "\n",
    "# Predictor names\n",
    "predictor_names = ['Jaccard Coefficient', 'Adamic-Adar Index', 'Geodesic Distance',\n",
    "                   'Common Neighbors', 'Degree Product']\n",
    "\n",
    "\n",
    "def compute_average_scores_from_split(edge_metadata, edgenonedge_data, predictors, predictor_names, test_size=0.2, random_state=69):\n",
    "    \"\"\"\n",
    "    Compute the average score for real edges and non-edges for each predictor based on a custom train-test split.\n",
    "\n",
    "    Parameters:\n",
    "        edge_metadata (list of np.ndarray): Feature data for each graph.\n",
    "        edgenonedge_data (list of np.ndarray): Label data (1 for real edges, 0 for non-edges).\n",
    "        predictors (list of np.ndarray): Predictor scores for each graph.\n",
    "        predictor_names (list): List of predictor names.\n",
    "        test_size (float): Fraction of the data to be used for testing.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with average scores for real and non-edges for each predictor.\n",
    "    \"\"\"\n",
    "    # Perform custom train-test split\n",
    "    def custom_train_test_split(edge_metadata, edgenonedge_data, test_size=0.2, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        num_graphs = len(edge_metadata)\n",
    "        shuffled_indices = np.random.permutation(num_graphs)\n",
    "        split_idx = int((1 - test_size) * num_graphs)\n",
    "        train_indices = shuffled_indices[:split_idx]\n",
    "        test_indices = shuffled_indices[split_idx:]\n",
    "        return train_indices, test_indices\n",
    "\n",
    "    # Split data\n",
    "    train_indices, test_indices = custom_train_test_split(edge_metadata, edgenonedge_data, test_size, random_state)\n",
    "\n",
    "    # Extract test data\n",
    "    test_metadata = [edge_metadata[i] for i in test_indices]\n",
    "    test_labels = [edgenonedge_data[i] for i in test_indices]\n",
    "    test_predictors = [predictors[i] for i in test_indices]\n",
    "\n",
    "    # Flatten test data for evaluation\n",
    "    X_test = np.vstack(test_metadata)\n",
    "    y_test = np.hstack(test_labels)\n",
    "    predictor_scores = np.vstack(test_predictors)\n",
    "\n",
    "    # Calculate average scores\n",
    "    results = {}\n",
    "    for i, name in enumerate(predictor_names):\n",
    "        scores = predictor_scores[:, i]\n",
    "        real_edge_scores = scores[y_test == 1]\n",
    "        non_edge_scores = scores[y_test == 0]\n",
    "\n",
    "        avg_real_edge_score = real_edge_scores.mean() if len(real_edge_scores) > 0 else 0\n",
    "        avg_non_edge_score = non_edge_scores.mean() if len(non_edge_scores) > 0 else 0\n",
    "\n",
    "        results[name] = {\n",
    "            \"Average Real Edge Score\": avg_real_edge_score,\n",
    "            \"Average Non-Edge Score\": avg_non_edge_score\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "average_scores = compute_average_scores_from_split(edge_metadata, edgenonedge_data, predictors, predictor_names)\n",
    "\n",
    "# Print results\n",
    "for predictor, scores in average_scores.items():\n",
    "    print(f\"{predictor}:\")\n",
    "    print(f\"  Average Real Edge Score: {scores['Average Real Edge Score']:.4f}\")\n",
    "    print(f\"  Average Non-Edge Score: {scores['Average Non-Edge Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
