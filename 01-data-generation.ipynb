{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e792abf-36b4-4c54-b89e-c2cd0f85f91e",
   "metadata": {},
   "source": [
    "# Meta Edge Prediction\n",
    "\n",
    "\n",
    "Virtual envorinemnt\n",
    "source .venv/bin/activate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Final project for Biological Networks, CSCI 3352\n",
    "\n",
    "Be a lil sloppy that's ok. Get it done first, refine, comment, cleanup, later\n",
    "\n",
    "Things we might wanna do:\n",
    "- Dig into the data more, see why diff models work better than others\n",
    "\n",
    "\n",
    "### Summary of Project\n",
    "\n",
    "Write this at the end as our project may change as we go... \n",
    "\n",
    "Don't forget to fill in the comments in each of the sections!\n",
    "\n",
    "Have instrucitons for importing the data and stuff\n",
    "\n",
    "\n",
    "\n",
    "### Citations\n",
    "\n",
    "Refine this aswell....\n",
    "\n",
    "@article{ghasemian2020stacking,\n",
    "  title = {Stacking models for nearly optimal link prediction in complex networks},\n",
    "  author = {Ghasemian, Amir and Hosseinmardi, Homa and Galstyan, Aram and Airoldi, Edoardo M and Clauset, Aaron},\n",
    "  journal = {Proceedings of the National Academy of Sciences},\n",
    "  volume = {117},\n",
    "  number = {38},\n",
    "  pages = {23393--23400},\n",
    "  year = {2020},\n",
    "  publisher = {National Acad Sciences},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a26e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "print(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c9228d-eb61-4a35-a5ec-ba13cd75f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.link_prediction import jaccard_coefficient\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c614639-49d2-44a8-88aa-ca83655c1cb6",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5b44ef-b6ce-4bb4-9892-b2bba71594dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle  \n",
    "\n",
    "# Load the data\n",
    "infile = open('./01-network-data/OLP_updated.pickle','rb')\n",
    "df = pickle.load(infile)\n",
    "\n",
    "# Filter df to get biological networks with > 200 nodes\n",
    "df_bio_200_nodes = df[(df['networkDomain'] == 'Biological') & (df['number_nodes'] > 200)]\n",
    "\n",
    "####### Convert the data (dataframe format) into networ-x graphs #######\n",
    "\n",
    "# Only grab graphs from these subDomains\n",
    "subDomains = ['Metabolic', 'Protein interactions', 'Tissue']\n",
    "\n",
    "# Place to store the nx-graphs of each subDomain\n",
    "Gs_subDomains = [] \n",
    "\n",
    "for subDomain in subDomains:\n",
    "    \n",
    "    # Isolate df-graphs of this subDomain\n",
    "    df_subDomain = df_bio_200_nodes[(df_bio_200_nodes['subDomain'] == subDomain)]\n",
    "    \n",
    "    Gs_subDomain = [] # Place to store nx-graphs of a subDomain\n",
    "    \n",
    "    # On each df-graph, convert it to a nx-graph and store\n",
    "    for i in range(len(df_subDomain)):\n",
    "        \n",
    "        # Get list-edges from df-graph\n",
    "        df_subDomain_single_G = df_subDomain['edges_id'].iloc[i] \n",
    "        \n",
    "        # Place to store tuple-edges\n",
    "        G_tuple_list = [] \n",
    "        \n",
    "        # Convert df edges into tuples\n",
    "        for x in df_subDomain_single_G:\n",
    "            G_tuple_list.append(tuple(x))\n",
    "            \n",
    "        # Convert the tuple list to a nx-graph\n",
    "        G_nx = nx.from_edgelist(G_tuple_list)\n",
    "            \n",
    "        # Add the nx-graph to Gs_metabolic\n",
    "        Gs_subDomain.append(G_nx) \n",
    "        \n",
    "    Gs_subDomains.append(Gs_subDomain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f43fad-b013-45e9-b2e7-721db099de9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(len(Gs_subDomains)): # On each subDomain print...\\n    \\n    Gs = Gs_subDomains[i] # Graphs of current subDomain\\n    \\n    print('Network subDomain:', subDomains[i])\\n    \\n    graph_count = len(Gs)\\n    print('# of graphs:', graph_count)\\n    \\n    avg_n = np.mean([len(G.nodes) for G in Gs])\\n    print(f'Avg number of nodes, n  = {avg_n}')\\n    \\n    avg_m = np.mean([len(G.edges) for G in Gs])\\n    print(f'Avg number of edges, m  = {avg_m}')\\n\\n    kmeans = []\\n    for G in Gs:\\n        kmeans.append(2 * G.number_of_edges() / G.number_of_nodes())\\n    avg_kmeans = np.mean(kmeans)\\n    print(f'Avg mean degree,    <k> = %5.2f' % avg_kmeans)\\n    \\n    avg_C = np.mean([nx.transitivity(G) for G in Gs])\\n    print(f'Avg clustering coefficient, C     = %5.2f' % avg_C)\\n    \\n    # avg_ellmean = np.mean([compute_MGD(G) for G in Gs]) \\n    # print(f'Avg mean geodesic distance, <ell> = %5.2f' % avg_ellmean)\\n    \\n    print('Sample rediculograms of subDomain:', subDomains[i])\\n    g1, g2 = np.random.choice(range(graph_count), 2, replace=False) # Randomly pick 2 graphs to display    \\n    nx.draw_spring(Gs[g1], node_size=10) # Rediculogram of a graph\\n    plt.show()\\n    nx.draw_spring(Gs[g2], node_size=10) # Rediculogram of a graph\\n    plt.show()\\n    \\n    print('\\n') # Space out different subDomains\\n    \\n    \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print stats on the data\n",
    "\n",
    "\n",
    "# # MGD function from homework 4\n",
    "# def compute_MGD(G):\n",
    "#     # input : a networkx graph G\n",
    "#     # output: the mean geodesic path length (defined in Lecture 2)\n",
    "\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     shortest_paths_data = list(nx.all_pairs_shortest_path_length(G)) # Get data of all shortest paths\n",
    "#     shortest_paths = []\n",
    "#     for i in shortest_paths_data: # Iterate through each node in the array/dict data\n",
    "#         for j in i[1].values(): # Isolate the geodesics for this node\n",
    "#             if j != 0 and j != np.inf: # Ensure geodesic is not 0 or infinity\n",
    "#                 shortest_paths.append(j)\n",
    "                \n",
    "#     if len(shortest_paths) == 0: # If empty graph, return geodesic dist of inf.\n",
    "#         return float('inf') # It needs to returns somehting if no edges, or else we get a divide by zero error\n",
    "#     else: \n",
    "#         MGD = sum(shortest_paths) / len(shortest_paths) # Calculate MGD from shortest paths\n",
    "#         return MGD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(len(Gs_subDomains)): # On each subDomain print...\n",
    "    \n",
    "    Gs = Gs_subDomains[i] # Graphs of current subDomain\n",
    "    \n",
    "    print('Network subDomain:', subDomains[i])\n",
    "    \n",
    "    graph_count = len(Gs)\n",
    "    print('# of graphs:', graph_count)\n",
    "    \n",
    "    avg_n = np.mean([len(G.nodes) for G in Gs])\n",
    "    print(f'Avg number of nodes, n  = {avg_n}')\n",
    "    \n",
    "    avg_m = np.mean([len(G.edges) for G in Gs])\n",
    "    print(f'Avg number of edges, m  = {avg_m}')\n",
    "\n",
    "    kmeans = []\n",
    "    for G in Gs:\n",
    "        kmeans.append(2 * G.number_of_edges() / G.number_of_nodes())\n",
    "    avg_kmeans = np.mean(kmeans)\n",
    "    print(f'Avg mean degree,    <k> = %5.2f' % avg_kmeans)\n",
    "    \n",
    "    avg_C = np.mean([nx.transitivity(G) for G in Gs])\n",
    "    print(f'Avg clustering coefficient, C     = %5.2f' % avg_C)\n",
    "    \n",
    "    # avg_ellmean = np.mean([compute_MGD(G) for G in Gs]) \n",
    "    # print(f'Avg mean geodesic distance, <ell> = %5.2f' % avg_ellmean)\n",
    "    \n",
    "    print('Sample rediculograms of subDomain:', subDomains[i])\n",
    "    g1, g2 = np.random.choice(range(graph_count), 2, replace=False) # Randomly pick 2 graphs to display    \n",
    "    nx.draw_spring(Gs[g1], node_size=10) # Rediculogram of a graph\n",
    "    plt.show()\n",
    "    nx.draw_spring(Gs[g2], node_size=10) # Rediculogram of a graph\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n') # Space out different subDomains\n",
    "    \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576d664-9dd7-42ca-8862-9882c4923990",
   "metadata": {},
   "source": [
    "# Run Edge Prediction on Graphs\n",
    "\n",
    "Some cool description stuff abt this section maybe idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ffa180-f625-4448-97e2-451990243069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 619 nodes and 1501 edges\n",
      "Edges observed 1196\n",
      "Edges missing 305\n",
      "Example edge from edges_o: (0, 52)\n",
      "\n",
      "\n",
      "G missing: Graph with 312 nodes and 305 edges\n"
     ]
    }
   ],
   "source": [
    "# Mage G-Observerd and G-Missing\n",
    "\n",
    "# !!!!!!!!!!!\n",
    "# To start, just do everything on the subDomain: metabolic\n",
    "Gs = Gs_subDomains[0]\n",
    "\n",
    "seed = 630\n",
    "alpha = 0.8 # Number of edges to observe\n",
    "\n",
    "# IMPORTANT!!!\n",
    "# Now instead of being a graph, the nodes and edges will be represented as a list\n",
    "edges_o = [] # G-Observed\n",
    "edges_missing = [] # G-Missing\n",
    "nodes = []\n",
    "\n",
    "for G in Gs:\n",
    "    G_nodes = []\n",
    "    for node in G.nodes():\n",
    "        G_nodes.append(node)\n",
    "    nodes.append(G_nodes)\n",
    "    \n",
    "    edge_o = []\n",
    "    edge_missing = []\n",
    "    for edge in G.edges():\n",
    "        if alpha > np.random.rand():\n",
    "            edge_o.append(edge)\n",
    "        else:\n",
    "            edge_missing.append(edge)\n",
    "    edges_o.append(edge_o)\n",
    "    edges_missing.append(edge_missing)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Convert the edges into graphs\n",
    "Gs_o = []\n",
    "Gs_missing = []\n",
    "\n",
    "for e_o, e_missing in zip(edges_o, edges_missing):\n",
    "    \n",
    "    # Create the graphs\n",
    "    G_o = nx.Graph()\n",
    "    G_missing = nx.Graph()\n",
    "    \n",
    "    # Add edges to graphs\n",
    "    G_o.add_edges_from(e_o)\n",
    "    G_missing.add_edges_from(e_missing)\n",
    "    \n",
    "    # Add graphs to array of graphs\n",
    "    Gs_o.append(G_o)\n",
    "    Gs_missing.append(G_missing)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Sanity check\n",
    "g = 3\n",
    "print(Gs[g])\n",
    "print('Edges observed', len(edges_o[g]))\n",
    "print('Edges missing', len(edges_missing[g]))\n",
    "print(\"Example edge from edges_o:\", edges_o[g][4])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('G missing:', Gs_missing[g])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65557e02",
   "metadata": {},
   "source": [
    "# Get Lists of edge/nonedge Data\n",
    "\n",
    "This data tells for each potential new edge, if it was actually a nonedge, it will have a 0, if it was actually an edge, it will have a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "090fa024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363242, 1)\n"
     ]
    }
   ],
   "source": [
    "def create_edgenonedge_data(G_o, G_missing):\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for u, v in nx.non_edges(G_o):\n",
    "        if G_missing.has_edge(u,v):\n",
    "            data.append(1)\n",
    "        else:\n",
    "            data.append(0)\n",
    "        \n",
    "    # Convert to NumPy array and reshape to (N, 1)\n",
    "    return np.array(data).reshape(-1, 1)\n",
    "\n",
    "edgenonedge_data = [] # Place to store predictions\n",
    "\n",
    "for G_o, G_missing in zip(Gs_o, Gs_missing): # Create edgenonedge_data on each graph\n",
    "    d = create_edgenonedge_data(G_o, G_missing)\n",
    "    edgenonedge_data.append(d)\n",
    "\n",
    "print(edgenonedge_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1290335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for later use\n",
    "\n",
    "# Save data \n",
    "with open('04-edgenonedge-data/edgenonedge_data.pkl', 'wb') as f:\n",
    "    pickle.dump(edgenonedge_data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7bf871-a330-499d-b6c3-cd55c1501169",
   "metadata": {},
   "source": [
    "## Run predictors on the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "045ef24f-6ac6-44f3-9efd-00f898056cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363242, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run jaccard edge predictor on graphs\n",
    "\n",
    "# Function to compute edge predictions on all edges in a single graph\n",
    "def predictor_jaccard(G_o):\n",
    "\n",
    "    # Compute predictor scores\n",
    "    predictions = dict(((u, v), p) for u, v, p in nx.jaccard_coefficient(G_o))\n",
    "    \n",
    "    ordered_predictions = []\n",
    "\n",
    "    # Grab predictor scores in the same order as the other predictor functions\n",
    "    for u, v in nx.non_edges(G_o):\n",
    "        p = predictions.get((u, v))\n",
    "        ordered_predictions.append(p)\n",
    "        \n",
    "    # Convert to NumPy array and reshape to (N, 1)\n",
    "    return np.array(ordered_predictions).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "jacc_edge_scores = [] # Place to store predictions\n",
    "\n",
    "for G_o in Gs_o: # Make predictions on each graph\n",
    "    p = predictor_jaccard(G_o)\n",
    "    jacc_edge_scores.append(p)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "jacc_edge_scores[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2efd5bc8-f086-4cb5-b2ca-84e7b69e9498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAfter switching to VS Code from Jupyter Notebook to speed up my\\nworkflow, parallel proscessing started throwing tons of errors. So\\nI will be switching to a for loop. On VS Code the for loop actually\\nPerforms about the same as the parallel proscessing.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run adamic-adar edge predictor on graphs\n",
    "\n",
    "# Function to compute edge predictions on all edges in a single graph\n",
    "def predictor_adamic_adar(G_o):\n",
    "\n",
    "    # Compute predictor scores\n",
    "    predictions = dict(((u, v), p) for u, v, p in nx.adamic_adar_index(G_o))\n",
    "    \n",
    "    ordered_predictions = []\n",
    "\n",
    "    # Grab predictor scores in the same order as the other predictor functions\n",
    "    for u, v in nx.non_edges(G_o):\n",
    "        p = predictions.get((u, v))\n",
    "        ordered_predictions.append(p)\n",
    "        \n",
    "    # Convert to NumPy array and reshape to (N, 1)\n",
    "    return np.array(ordered_predictions).reshape(-1, 1)\n",
    "\n",
    "\n",
    "adamic_adar_edge_scores = [] # Place to store predictions\n",
    "\n",
    "for G_o in Gs_o: # Make predictions on each graph\n",
    "    p = predictor_adamic_adar(G_o)\n",
    "    adamic_adar_edge_scores.append(p)\n",
    "\n",
    "'''\n",
    "After switching to VS Code from Jupyter Notebook to speed up my\n",
    "workflow, parallel proscessing started throwing tons of errors. So\n",
    "I will be switching to a for loop. On VS Code the for loop actually\n",
    "Performs about the same as the parallel proscessing.\n",
    "'''\n",
    "# # Use parallel proscessing to speed up calculations!\n",
    "# with ProcessPoolExecutor() as executor: # Use max number of executors\n",
    "#     jacc_edge_scores = list(\n",
    "#         executor.map(predictor_jaccard, Gs_o) # Pass each graph's edges into the predictor\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a31818-fb96-42a5-96f1-8d3e89f41c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run geodesic edge predictor on graphs\n",
    "\n",
    "# Function to compute edge predictions on all edges in a single graph\n",
    "def predictor_geodesic(G_o):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for u, v in nx.non_edges(G_o):\n",
    "        try:\n",
    "            score = nx.shortest_path_length(G_o, u, v)\n",
    "            predictions.append(score)\n",
    "        except nx.NetworkXNoPath: \n",
    "            # No path - set score to 0\n",
    "            predictions.append(0)\n",
    "        \n",
    "    # Convert to NumPy array and reshape to (N, 1)\n",
    "    return np.array(predictions).reshape(-1, 1)\n",
    "\n",
    "geodesic_edge_scores = [] # Place to store predictions\n",
    "\n",
    "for G_o in Gs_o: # Make predictions on each graph\n",
    "    p = predictor_geodesic(G_o)\n",
    "    geodesic_edge_scores.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e23aea4-0854-481c-ade6-b656f8d608d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run common-neighbors edge predictor on graphs\n",
    "\n",
    "# Function to compute edge predictions on all edges in a single graph\n",
    "def predictor_common_neighbors(G_o):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for u, v in nx.non_edges(G_o):\n",
    "        score = len(list(nx.common_neighbors(G_o, u, v)))\n",
    "        predictions.append(score)\n",
    "        \n",
    "    # Convert to NumPy array and reshape to (N, 1)\n",
    "    return np.array(predictions).reshape(-1, 1)\n",
    "\n",
    "common_neighbors_edge_scores = [] # Place to store predictions\n",
    "\n",
    "for G_o in Gs_o: # Make predictions on each graph\n",
    "    p = predictor_common_neighbors(G_o)\n",
    "    common_neighbors_edge_scores.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd26e970-45e3-46a3-9f89-126836545d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run degree-product edge predictor on graphs\n",
    "\n",
    "# Function to compute edge predictions on all edges in a single graph\n",
    "def predictor_degree_prod(G_o):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for u, v in nx.non_edges(G_o):\n",
    "        score = G_o.degree[u] * G_o.degree[v]\n",
    "        predictions.append(score)\n",
    "        \n",
    "    # Convert to NumPy array and reshape to (N, 1)\n",
    "    return np.array(predictions).reshape(-1, 1)\n",
    "\n",
    "degree_prod_edge_scores = [] # Place to store predictions\n",
    "\n",
    "for G_o in Gs_o: # Make predictions on each graph\n",
    "    p = predictor_degree_prod(G_o)\n",
    "    degree_prod_edge_scores.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93ef720c-c1f1-4c1a-bd9b-52c5cd0cfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict missing edges with baseline predictor (random)\n",
    "\n",
    "baseline_edge_scores = [] # Place to store predictions\n",
    "\n",
    "for G in jacc_edge_scores:\n",
    "    predictions = []\n",
    "    for edge in G:\n",
    "        predictions.append(np.random.uniform(0,1))\n",
    "    baseline_edge_scores.append(np.array(predictions).reshape(-1, 1))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368c1a45-b161-475e-9ab3-edfd69558d92",
   "metadata": {},
   "source": [
    "## Sanity Check!\n",
    "\n",
    "Im scared lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30294d0-8777-4dd9-b2bc-21e58ede06e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor:   jacc_edge_scores   sameple score Edge Score:   [0.]\n",
      "Predictor:   adamic_adar_edge_scores   sameple score Edge Score:   [0.]\n",
      "Predictor:   geodesic_edge_scores   sameple score Edge Score:   [3]\n",
      "Predictor:   common_neighbors_edge_scores   sameple score Edge Score:   [0]\n",
      "Predictor:   degree_prod_edge_scores   sameple score Edge Score:   [155]\n",
      "Predictor:   baseline_edge_scores   sameple score Edge Score:   [0.31213935]\n",
      "\n",
      "\n",
      "Predictor:   jacc_edge_scores   shape:   (363242, 1)\n",
      "Predictor:   adamic_adar_edge_scores   shape:   (363242, 1)\n",
      "Predictor:   geodesic_edge_scores   shape:   (363242, 1)\n",
      "Predictor:   common_neighbors_edge_scores   shape:   (363242, 1)\n",
      "Predictor:   degree_prod_edge_scores   shape:   (363242, 1)\n",
      "Predictor:   baseline_edge_scores   shape:   (363242, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# All predictior edge scores:\n",
    "\n",
    "jacc_edge_scores\n",
    "adamic_adar_edge_scores\n",
    "geodesic_edge_scores\n",
    "common_neighbors_edge_scores\n",
    "degree_prod_edge_scores\n",
    "baseline_edge_scores\n",
    "'''\n",
    "\n",
    "predictor_names = ['jacc_edge_scores', 'adamic_adar_edge_scores','geodesic_edge_scores',\n",
    "                   'common_neighbors_edge_scores','degree_prod_edge_scores',\n",
    "                   'baseline_edge_scores']\n",
    "\n",
    "ps_grouped_together = [jacc_edge_scores, adamic_adar_edge_scores, geodesic_edge_scores,\n",
    "                               common_neighbors_edge_scores, degree_prod_edge_scores,\n",
    "                               baseline_edge_scores]\n",
    "\n",
    "g = 5 # Graph index\n",
    "e = 420 # Edge index\n",
    "\n",
    "\n",
    "for i in range(len(predictor_names)):\n",
    "    print(f'Predictor:   {predictor_names[i]}   sameple score Edge Score:   {ps_grouped_together[i][g][e]}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for i in range(len(predictor_names)):\n",
    "    print(f'Predictor:   {predictor_names[i]}   shape:   {ps_grouped_together[i][0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ee228-ad89-4aca-acb9-11b2d2396e06",
   "metadata": {},
   "source": [
    "## Save The Predictions\n",
    "\n",
    "Whew those predictions take forever to calculate. Lets save them so we don't have to run this code everytime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de8b591c-2144-4fa9-9373-b2539dafe54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = copy.deepcopy([jacc_edge_scores, adamic_adar_edge_scores, geodesic_edge_scores, \n",
    "              common_neighbors_edge_scores, degree_prod_edge_scores, \n",
    "             baseline_edge_scores])\n",
    "\n",
    "# Save data \n",
    "with open('02-predictor-data/raw/predictors.pkl', 'wb') as f:\n",
    "    pickle.dump(predictors, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c7f5c",
   "metadata": {},
   "source": [
    "# Get edge metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91bc4011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Completed the 300000 th iteration\n",
      "Sample predictor score for a graph: 0.006172839506172839\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Completed the 300000 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Sample predictor score for a graph: 0.06060606060606061\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Sample predictor score for a graph: 0.013513513513513514\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Completed the 300000 th iteration\n",
      "Sample predictor score for a graph: 0.006369426751592357\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Completed the 300000 th iteration\n",
      "Completed the 400000 th iteration\n",
      "Completed the 500000 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Sample predictor score for a graph: 0.005649717514124294\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Sample predictor score for a graph: 0.030927835051546393\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Sample predictor score for a graph: 0.0380952380952381\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Sample predictor score for a graph: 0.006060606060606061\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Completed the 300000 th iteration\n",
      "Sample predictor score for a graph: 0.03977272727272727\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Completed the 300000 th iteration\n",
      "Sample predictor score for a graph: 0.0851063829787234\n",
      "Completed the 0 th iteration\n",
      "Sample predictor score for a graph: 0.05128205128205128\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Sample predictor score for a graph: 0.10416666666666667\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Completed the 300000 th iteration\n",
      "Completed the 400000 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Sample predictor score for a graph: 0.010752688172043012\n",
      "Completed the 0 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Sample predictor score for a graph: 0.0\n",
      "Completed the 0 th iteration\n",
      "Completed the 100000 th iteration\n",
      "Completed the 200000 th iteration\n",
      "Sample predictor score for a graph: 0.007633587786259542\n",
      "Completed the 0 th iteration\n",
      "Sample predictor score for a graph: 0.023255813953488372\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Takes my laptop ~40 sec to run\n",
    "\n",
    "def create_edge_metadata(G_o, G_p):\n",
    "    data = []\n",
    "    \n",
    "    # Precompute graph-level metadata\n",
    "    node_count = G_o.number_of_nodes()\n",
    "    edge_count = G_o.number_of_edges()\n",
    "    density = nx.density(G_o)\n",
    "    avg_degree = sum(dict(G_o.degree()).values()) / node_count\n",
    "    clustering_coeff = nx.average_clustering(G_o)\n",
    "    jacc_edge_scores = G_p[0]\n",
    "    adamic_adar_edge_scores = G_p[1]\n",
    "    geodesic_edge_scores = G_p[2]\n",
    "    common_neighbors_edge_scores = G_p[3]\n",
    "    degree_prod_edge_scores = G_p[4]\n",
    "    \n",
    "    try:\n",
    "        diameter = nx.diameter(G_o) if nx.is_connected(G_o) else -1  # Use -1 for disconnected graphs\n",
    "    except nx.NetworkXError:\n",
    "        diameter = -1  # Handle cases where diameter cannot be computed\n",
    "    \n",
    "    num_connected_components = nx.number_connected_components(G_o)\n",
    "    \n",
    "    # Precompute node-level metadata\n",
    "    degrees = dict(G_o.degree())\n",
    "    pagerank = nx.pagerank(G_o)\n",
    "    \n",
    "    # Iterate over non-edges and compute edge metadata\n",
    "    i = 0\n",
    "    for u, v in nx.non_edges(G_o):  # Order maintained by nx.non_edges()\n",
    "        if i%100000 == 0:\n",
    "            print('Completed the', i,'th iteration')\n",
    "        # Edge-specific metadata\n",
    "        degree_u = degrees.get(u, 0)\n",
    "        degree_v = degrees.get(v, 0)\n",
    "        pagerank_u = pagerank.get(u, 0)\n",
    "        pagerank_v = pagerank.get(v, 0)\n",
    "        \n",
    "        # Combine edge and graph metadata\n",
    "        edge_entry = [\n",
    "            degree_u, degree_v,       # Node degrees\n",
    "            pagerank_u, pagerank_v,   # Node PageRank\n",
    "            node_count, edge_count,   # Graph size\n",
    "            density, avg_degree,      # Graph density and avg degree\n",
    "            diameter,                 # Graph diameter\n",
    "            num_connected_components, # Number of connected components\n",
    "            clustering_coeff,         # Avg clustering coefficient\n",
    "            jacc_edge_scores[i].item(), adamic_adar_edge_scores[i].item(),\n",
    "            geodesic_edge_scores[i].item(), common_neighbors_edge_scores[i].item(),\n",
    "            degree_prod_edge_scores[i].item()\n",
    "\n",
    "        ]\n",
    "        data.append(edge_entry)\n",
    "        i += 1\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    return np.array(data)\n",
    "\n",
    "# Example usage:\n",
    "edge_metadata = []  # Place to store metadata arrays\n",
    "\n",
    "for i in range(len(Gs_o)):  # Create edge metadata for each graph in Gs_o\n",
    "    G_o = Gs_o[i]\n",
    "    G_p = [] # Place to store predictor data for this graph\n",
    "    for p in predictors: # Over each predictor\n",
    "        G_p.append(p[i]) # Get this graphs predictor data\n",
    "    d = create_edge_metadata(G_o, G_p)\n",
    "    print('Sample predictor score for a graph:', G_p[0][0].item())\n",
    "\n",
    "    edge_metadata.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0817e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363242, 16)\n",
      "edge_metadata[0] shape: (363242, 16)\n",
      "Unique rows in edge_metadata[0]: 259893\n",
      "First 5 rows of edge_metadata[0]:\n",
      " [[ 1.61000000e+02  2.00000000e+00  4.00512687e-02  6.20650058e-04\n",
      "   8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      "  -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.17283951e-03\n",
      "   2.41363138e-01  2.00000000e+00  1.00000000e+00  3.22000000e+02]\n",
      " [ 1.61000000e+02  3.00000000e+00  4.00512687e-02  7.79806973e-04\n",
      "   8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      "  -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.13496933e-03\n",
      "   2.19593112e-01  2.00000000e+00  1.00000000e+00  4.83000000e+02]\n",
      " [ 1.61000000e+02  4.00000000e+00  4.00512687e-02  9.72611570e-04\n",
      "   8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      "  -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.09756098e-03\n",
      "   2.71085031e-01  2.00000000e+00  1.00000000e+00  6.44000000e+02]\n",
      " [ 1.61000000e+02  2.00000000e+00  4.00512687e-02  5.81520716e-04\n",
      "   8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      "  -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.17283951e-03\n",
      "   3.10667467e-01  2.00000000e+00  1.00000000e+00  3.22000000e+02]\n",
      " [ 1.61000000e+02  2.00000000e+00  4.00512687e-02  8.39637253e-04\n",
      "   8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      "  -1.00000000e+00  4.00000000e+00  1.08891926e-01  0.00000000e+00\n",
      "   0.00000000e+00  3.00000000e+00  0.00000000e+00  3.22000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Print shape of metadata for the first graph\n",
    "print(edge_metadata[0].shape)\n",
    "\n",
    "# Example for inspecting edge_metadata\n",
    "graph_index = 0  # Change this to inspect other graphs\n",
    "\n",
    "# Check shape of edge_metadata for the selected graph\n",
    "print(f\"edge_metadata[{graph_index}] shape:\", edge_metadata[graph_index].shape)\n",
    "\n",
    "# Check for constant or uniform data within the selected graph\n",
    "print(f\"Unique rows in edge_metadata[{graph_index}]:\", np.unique(edge_metadata[graph_index], axis=0).shape[0])\n",
    "\n",
    "# Inspect a few rows of the selected graph's edge metadata\n",
    "print(f\"First 5 rows of edge_metadata[{graph_index}]:\\n\", edge_metadata[graph_index][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "073d65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for later use\n",
    "\n",
    "# Takes ~\n",
    "\n",
    "# Save data \n",
    "with open('05-edge-metadata/edge_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(edge_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27c85605-3511-4cda-bc26-e6cf44241153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10889192561310057\n",
      "0.006172839506172839\n"
     ]
    }
   ],
   "source": [
    "print(edge_metadata[0][0][10])\n",
    "print(edge_metadata[0][0][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb3b0830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking first few edges...\n",
      "Edge (0, 2):\n",
      "  Metadata: [ 1.61000000e+02  2.00000000e+00  4.00512687e-02  6.20650058e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.17283951e-03\n",
      "  2.41363138e-01  2.00000000e+00  1.00000000e+00  3.22000000e+02]\n",
      "  Jaccard score: 0.006172839506172839\n",
      "  Computed Degree_u: 161, Degree_v: 2\n",
      "---\n",
      "Edge (0, 3):\n",
      "  Metadata: [ 1.61000000e+02  3.00000000e+00  4.00512687e-02  7.79806973e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.13496933e-03\n",
      "  2.19593112e-01  2.00000000e+00  1.00000000e+00  4.83000000e+02]\n",
      "  Jaccard score: 0.006134969325153374\n",
      "  Computed Degree_u: 161, Degree_v: 3\n",
      "---\n",
      "Edge (0, 4):\n",
      "  Metadata: [ 1.61000000e+02  4.00000000e+00  4.00512687e-02  9.72611570e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.09756098e-03\n",
      "  2.71085031e-01  2.00000000e+00  1.00000000e+00  6.44000000e+02]\n",
      "  Jaccard score: 0.006097560975609756\n",
      "  Computed Degree_u: 161, Degree_v: 4\n",
      "---\n",
      "Edge (0, 6):\n",
      "  Metadata: [ 1.61000000e+02  2.00000000e+00  4.00512687e-02  5.81520716e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  6.17283951e-03\n",
      "  3.10667467e-01  2.00000000e+00  1.00000000e+00  3.22000000e+02]\n",
      "  Jaccard score: 0.006172839506172839\n",
      "  Computed Degree_u: 161, Degree_v: 2\n",
      "---\n",
      "Edge (0, 7):\n",
      "  Metadata: [ 1.61000000e+02  2.00000000e+00  4.00512687e-02  8.39637253e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  3.22000000e+02]\n",
      "  Jaccard score: 0.0\n",
      "  Computed Degree_u: 161, Degree_v: 2\n",
      "---\n",
      "\n",
      "Checking last few edges...\n",
      "Edge (876, 878):\n",
      "  Metadata: [ 2.00000000e+00  2.00000000e+00  8.14283597e-04  6.35079805e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  4.00000000e+00]\n",
      "  Jaccard score: 0.0\n",
      "  Computed Degree_u: 2, Degree_v: 2\n",
      "---\n",
      "Edge (876, 879):\n",
      "  Metadata: [ 2.00000000e+00  5.00000000e+00  8.14283597e-04  1.35973520e-03\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  1.00000000e+01]\n",
      "  Jaccard score: 0.0\n",
      "  Computed Degree_u: 2, Degree_v: 5\n",
      "---\n",
      "Edge (877, 878):\n",
      "  Metadata: [ 1.00000000e+00  2.00000000e+00  3.94531485e-04  6.35079805e-04\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  2.00000000e+00]\n",
      "  Jaccard score: 0.0\n",
      "  Computed Degree_u: 1, Degree_v: 2\n",
      "---\n",
      "Edge (877, 879):\n",
      "  Metadata: [ 1.00000000e+00  5.00000000e+00  3.94531485e-04  1.35973520e-03\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  5.00000000e+00]\n",
      "  Jaccard score: 0.0\n",
      "  Computed Degree_u: 1, Degree_v: 5\n",
      "---\n",
      "Edge (878, 879):\n",
      "  Metadata: [ 2.00000000e+00  5.00000000e+00  6.35079805e-04  1.35973520e-03\n",
      "  8.55000000e+02  1.84300000e+03  5.04813947e-03  4.31111111e+00\n",
      " -1.00000000e+00  4.00000000e+00  1.08891926e-01  0.00000000e+00\n",
      "  0.00000000e+00  4.00000000e+00  0.00000000e+00  1.00000000e+01]\n",
      "  Jaccard score: 0.0\n",
      "  Computed Degree_u: 2, Degree_v: 5\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Function to validate metadata for specific edges\n",
    "def validate_metadata(G_o, metadata, predictor_scores, num_edges=5):\n",
    "    \"\"\"\n",
    "    Validate metadata and predictor scores for the first and last few edges.\n",
    "    \n",
    "    Args:\n",
    "        G_o (Graph): The original graph.\n",
    "        metadata (np.array): The computed metadata for edges.\n",
    "        predictor_scores (np.array): Predictor scores (e.g., Jaccard) for edges.\n",
    "        num_edges (int): Number of edges to check from the start and end.\n",
    "    \"\"\"\n",
    "    # Get the list of non-edges\n",
    "    non_edges = list(nx.non_edges(G_o))\n",
    "    \n",
    "    # Check first few edges\n",
    "    print(\"Checking first few edges...\")\n",
    "    for i, (u, v) in enumerate(non_edges[:num_edges]):\n",
    "        print(f\"Edge ({u}, {v}):\")\n",
    "        print(f\"  Metadata: {metadata[i]}\")\n",
    "        print(f\"  Jaccard score: {predictor_scores[i][0]}\")  # Assuming predictor_scores is reshaped (-1, 1)\n",
    "        # Optional: Compute metadata on-the-fly and compare\n",
    "        degree_u = G_o.degree(u)\n",
    "        degree_v = G_o.degree(v)\n",
    "        print(f\"  Computed Degree_u: {degree_u}, Degree_v: {degree_v}\")\n",
    "        print(\"---\")\n",
    "\n",
    "    # Check last few edges\n",
    "    print(\"\\nChecking last few edges...\")\n",
    "    for i, (u, v) in enumerate(non_edges[-num_edges:]):\n",
    "        idx = len(non_edges) - num_edges + i  # Adjust index for metadata and predictors\n",
    "        print(f\"Edge ({u}, {v}):\")\n",
    "        print(f\"  Metadata: {metadata[idx]}\")\n",
    "        print(f\"  Jaccard score: {predictor_scores[idx][0]}\")\n",
    "        # Optional: Compute metadata on-the-fly and compare\n",
    "        degree_u = G_o.degree(u)\n",
    "        degree_v = G_o.degree(v)\n",
    "        print(f\"  Computed Degree_u: {degree_u}, Degree_v: {degree_v}\")\n",
    "        print(\"---\")\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "graph_index = 0  # Choose the graph index to test\n",
    "G_o = Gs_o[graph_index]\n",
    "metadata = edge_metadata[graph_index]\n",
    "predictor_scores = jacc_edge_scores[graph_index]\n",
    "\n",
    "# Validate metadata for the first and last few edges\n",
    "validate_metadata(G_o, metadata, predictor_scores, num_edges=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39ce3957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing first few edges...\n",
      "Edge (0, 2):\n",
      "  Pipeline Metadata (G_o):\n",
      "    Jaccard score: 0.006173\n",
      "    Degree_u: 161.000000, Degree_v: 2.000000\n",
      "  Freshly Computed Metadata (G_o): {'Jaccard': 0.006173, 'Degree_u': 161, 'Degree_v': 2}\n",
      "  Metadata from Original Graph (G_s): {'Jaccard': 0.005291, 'Degree_u': 188, 'Degree_v': 2}\n",
      "---\n",
      "Edge (0, 3):\n",
      "  Pipeline Metadata (G_o):\n",
      "    Jaccard score: 0.006135\n",
      "    Degree_u: 161.000000, Degree_v: 3.000000\n",
      "  Freshly Computed Metadata (G_o): {'Jaccard': 0.006135, 'Degree_u': 161, 'Degree_v': 3}\n",
      "  Metadata from Original Graph (G_s): {'Jaccard': 0.010582, 'Degree_u': 188, 'Degree_v': 3}\n",
      "---\n",
      "Edge (0, 4):\n",
      "  Pipeline Metadata (G_o):\n",
      "    Jaccard score: 0.006098\n",
      "    Degree_u: 161.000000, Degree_v: 4.000000\n",
      "  Freshly Computed Metadata (G_o): {'Jaccard': 0.006098, 'Degree_u': 161, 'Degree_v': 4}\n",
      "  Metadata from Original Graph (G_s): {'Jaccard': 0.010471, 'Degree_u': 188, 'Degree_v': 5}\n",
      "---\n",
      "\n",
      "Comparing last few edges...\n",
      "Edge (877, 878):\n",
      "  Pipeline Metadata (G_o):\n",
      "    Jaccard score: 0.0\n",
      "    Degree_u: 1.000000, Degree_v: 2.000000\n",
      "  Freshly Computed Metadata (G_o): {'Jaccard': 0.0, 'Degree_u': 1, 'Degree_v': 2}\n",
      "  Metadata from Original Graph (G_s): {'Jaccard': 0.0, 'Degree_u': 2, 'Degree_v': 4}\n",
      "---\n",
      "Edge (877, 879):\n",
      "  Pipeline Metadata (G_o):\n",
      "    Jaccard score: 0.0\n",
      "    Degree_u: 1.000000, Degree_v: 5.000000\n",
      "  Freshly Computed Metadata (G_o): {'Jaccard': 0.0, 'Degree_u': 1, 'Degree_v': 5}\n",
      "  Metadata from Original Graph (G_s): {'Jaccard': 0.0, 'Degree_u': 2, 'Degree_v': 7}\n",
      "---\n",
      "Edge (878, 879):\n",
      "  Pipeline Metadata (G_o):\n",
      "    Jaccard score: 0.0\n",
      "    Degree_u: 2.000000, Degree_v: 5.000000\n",
      "  Freshly Computed Metadata (G_o): {'Jaccard': 0.0, 'Degree_u': 2, 'Degree_v': 5}\n",
      "  Metadata from Original Graph (G_s): {'Jaccard': 0.0, 'Degree_u': 4, 'Degree_v': 7}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def validate_metadata_comparisons(G_o, G_s, metadata, predictor_scores, num_edges=3):\n",
    "    \"\"\"\n",
    "    Compare Jaccard score, Degree_u, and Degree_v for observed graph (G_o),\n",
    "    freshly computed values, and original graph (G_s).\n",
    "\n",
    "    Args:\n",
    "        G_o (Graph): The observed graph.\n",
    "        G_s (Graph): The original graph.\n",
    "        metadata (np.array): The computed metadata for edges in G_o.\n",
    "        predictor_scores (np.array): Predictor scores (e.g., Jaccard) for edges in G_o.\n",
    "        num_edges (int): Number of edges to check from the start and end.\n",
    "    \"\"\"\n",
    "    # Get the list of non-edges in G_o and edges in G_s\n",
    "    non_edges = list(nx.non_edges(G_o))\n",
    "    original_edges = list(G_s.edges())\n",
    "    \n",
    "    def compute_metadata(G, u, v):\n",
    "        \"\"\"\n",
    "        Compute metadata stats from scratch for a given edge (u, v) in graph G.\n",
    "        \"\"\"\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        jaccard = list(nx.jaccard_coefficient(G, [(u, v)]))[0][2] if G.has_edge(u, v) or not nx.is_directed(G) else 0\n",
    "        return {\n",
    "            \"Jaccard\": round(jaccard, 6),\n",
    "            \"Degree_u\": round(degree_u, 6),\n",
    "            \"Degree_v\": round(degree_v, 6)\n",
    "        }\n",
    "    \n",
    "    # Check first few edges\n",
    "    print(\"Comparing first few edges...\")\n",
    "    for i, (u, v) in enumerate(non_edges[:num_edges]):\n",
    "        print(f\"Edge ({u}, {v}):\")\n",
    "        \n",
    "        # Pipeline metadata\n",
    "        print(f\"  Pipeline Metadata (G_o):\")\n",
    "        print(f\"    Jaccard score: {round(predictor_scores[i][0], 6)}\")\n",
    "        print(f\"    Degree_u: {metadata[i][0]:.6f}, Degree_v: {metadata[i][1]:.6f}\")\n",
    "        \n",
    "        # Freshly computed metadata for G_o\n",
    "        fresh_meta = compute_metadata(G_o, u, v)\n",
    "        print(f\"  Freshly Computed Metadata (G_o): {fresh_meta}\")\n",
    "        \n",
    "        # Freshly computed metadata for G_s\n",
    "        orig_meta = compute_metadata(G_s, u, v)\n",
    "        print(f\"  Metadata from Original Graph (G_s): {orig_meta}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    # Check last few edges\n",
    "    print(\"\\nComparing last few edges...\")\n",
    "    for i, (u, v) in enumerate(non_edges[-num_edges:]):\n",
    "        idx = len(non_edges) - num_edges + i\n",
    "        print(f\"Edge ({u}, {v}):\")\n",
    "        \n",
    "        # Pipeline metadata\n",
    "        print(f\"  Pipeline Metadata (G_o):\")\n",
    "        print(f\"    Jaccard score: {round(predictor_scores[idx][0], 6)}\")\n",
    "        print(f\"    Degree_u: {metadata[idx][0]:.6f}, Degree_v: {metadata[idx][1]:.6f}\")\n",
    "        \n",
    "        # Freshly computed metadata for G_o\n",
    "        fresh_meta = compute_metadata(G_o, u, v)\n",
    "        print(f\"  Freshly Computed Metadata (G_o): {fresh_meta}\")\n",
    "        \n",
    "        # Freshly computed metadata for G_s\n",
    "        orig_meta = compute_metadata(G_s, u, v)\n",
    "        print(f\"  Metadata from Original Graph (G_s): {orig_meta}\")\n",
    "        print(\"---\")\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "graph_index = 0  # Test the first graph\n",
    "G_o = Gs_o[graph_index]  # Observed graph\n",
    "G_s = Gs[graph_index]    # Original graph\n",
    "metadata = edge_metadata[graph_index]\n",
    "predictor_scores = jacc_edge_scores[graph_index]\n",
    "\n",
    "# Validate and compare metadata\n",
    "validate_metadata_comparisons(G_o, G_s, metadata, predictor_scores, num_edges=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb5db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
